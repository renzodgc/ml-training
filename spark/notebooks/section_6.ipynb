{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef15155-cbf7-4166-9ef0-e011afc8b990",
   "metadata": {},
   "source": [
    "# Section 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e42ebc6-12fa-4ec7-913a-68c98b67b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import sys\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79ea0a3a-e6cd-498c-88f5-9cc2ce5739bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession (Note, the config section is only for Windows!)\n",
    "spark = SparkSession.builder.appName(\"SparkSQL\").master(\"local[*]\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26984ca6-5937-4377-9013-ab3a46689a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"../spark_course_resources\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8296144-0521-46e0-a636-11525dbf7776",
   "metadata": {},
   "source": [
    "## Popular Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db51adaf-5e7b-42e7-8b55-10bbbb3ec2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training recommendation model...\n",
      "Top 10 recommendations for user ID 5\n",
      "Unzipped (1995)8.09460735321045\n",
      "Roommates (1995)7.99899435043335\n",
      "Dangerous Beauty (1998)7.425593376159668\n",
      "Stalker (1979)7.196524620056152\n",
      "Carried Away (1996)6.729679584503174\n",
      "Wings of Desire (1987)6.182162761688232\n",
      "Maya Lin: A Strong Clear Vision (1994)6.112681865692139\n",
      "Magic Hour, The (1998)6.112635135650635\n",
      "Kaspar Hauser (1993)6.046888828277588\n",
      "Chungking Express (1994)5.958040237426758\n"
     ]
    }
   ],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with codecs.open(f\"{DATA_ROOT}/ml-100k/u.item\", \"r\", encoding='ISO-8859-1', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('|')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames\n",
    "\n",
    "moviesSchema = StructType([ \\\n",
    "                     StructField(\"userID\", IntegerType(), True), \\\n",
    "                     StructField(\"movieID\", IntegerType(), True), \\\n",
    "                     StructField(\"rating\", IntegerType(), True), \\\n",
    "                     StructField(\"timestamp\", LongType(), True)])\n",
    "    \n",
    "names = loadMovieNames()\n",
    "    \n",
    "ratings = spark.read.option(\"sep\", \"\\t\").schema(moviesSchema) \\\n",
    "    .csv(f\"{DATA_ROOT}/ml-100k/u.data\")\n",
    "    \n",
    "print(\"Training recommendation model...\")\n",
    "\n",
    "als = ALS().setMaxIter(5).setRegParam(0.01).setUserCol(\"userID\").setItemCol(\"movieID\") \\\n",
    "    .setRatingCol(\"rating\")\n",
    "    \n",
    "model = als.fit(ratings)\n",
    "\n",
    "# Manually construct a dataframe of the user ID's we want recs for\n",
    "userID = 5\n",
    "userSchema = StructType([StructField(\"userID\", IntegerType(), True)])\n",
    "users = spark.createDataFrame([[userID,]], userSchema)\n",
    "\n",
    "recommendations = model.recommendForUserSubset(users, 10).collect()\n",
    "\n",
    "print(\"Top 10 recommendations for user ID \" + str(userID))\n",
    "\n",
    "for userRecs in recommendations:\n",
    "    myRecs = userRecs[1]  #userRecs is (userID, [Row(movieId, rating), Row(movieID, rating)...])\n",
    "    for rec in myRecs: #my Recs is just the column of recs for the user\n",
    "        movie = rec[0] #For each rec in the list, extract the movie ID and rating\n",
    "        rating = rec[1]\n",
    "        movieName = names[movie]\n",
    "        print(movieName + str(rating))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7996c7f3-000a-4cc3-b799-732b5233682d",
   "metadata": {},
   "source": [
    "### Height Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a829a620-9a4e-4dab-806a-e65ce8d6dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up our data and convert it to the format MLLib expects.\n",
    "inputLines = spark.sparkContext.textFile(f\"{DATA_ROOT}/regression.txt\")\n",
    "data = inputLines.map(lambda x: x.split(\",\")).map(lambda x: (float(x[0]), Vectors.dense(float(x[1]))))\n",
    "\n",
    "# Convert this RDD to a DataFrame\n",
    "colNames = [\"label\", \"features\"]\n",
    "df = data.toDF(colNames)\n",
    "\n",
    "# Note, there are lots of cases where you can avoid going from an RDD to a DataFrame.\n",
    "# Perhaps you're importing data from a real database. Or you are using structured streaming\n",
    "# to get your data.\n",
    "\n",
    "# Let's split our data into training data and testing data\n",
    "trainTest = df.randomSplit([0.5, 0.5])\n",
    "trainingDF = trainTest[0]\n",
    "testDF = trainTest[1]\n",
    "\n",
    "# Now create our linear regression model\n",
    "lir = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Train the model using our training data\n",
    "model = lir.fit(trainingDF)\n",
    "\n",
    "# Now see if we can predict values in our test data.\n",
    "# Generate predictions using our linear regression model for all features in our\n",
    "# test dataframe:\n",
    "fullPredictions = model.transform(testDF).cache()\n",
    "\n",
    "# Extract the predictions and the \"known\" correct labels.\n",
    "predictions = fullPredictions.select(\"prediction\").rdd.map(lambda x: x[0])\n",
    "labels = fullPredictions.select(\"label\").rdd.map(lambda x: x[0])\n",
    "\n",
    "# Zip them together\n",
    "predictionAndLabel = predictions.zip(labels).collect()\n",
    "\n",
    "# Print out the predicted and actual values for each point\n",
    "for prediction in predictionAndLabel:\n",
    "  pass # print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf568e-d8f9-43c5-b606-b30b240be6b5",
   "metadata": {},
   "source": [
    "### Real State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ea95897-e933-433e-8ca8-6810429d9667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19.449999999999996, 11.6)\n",
      "(19.449999999999996, 12.8)\n",
      "(19.449999999999996, 12.9)\n",
      "(12.800000000000011, 13.7)\n",
      "(12.800000000000011, 13.8)\n",
      "(19.449999999999996, 14.7)\n",
      "(12.8, 15.0)\n",
      "(17.8, 15.4)\n",
      "(19.449999999999996, 15.5)\n",
      "(12.8, 15.6)\n",
      "(17.8, 15.9)\n",
      "(12.800000000000011, 16.1)\n",
      "(19.449999999999996, 16.7)\n",
      "(12.8, 17.4)\n",
      "(20.433333333333337, 18.3)\n",
      "(19.449999999999996, 18.8)\n",
      "(20.433333333333337, 19.0)\n",
      "(15.8, 19.2)\n",
      "(26.518518518518526, 21.3)\n",
      "(30.599999999999994, 22.0)\n",
      "(12.8, 22.1)\n",
      "(20.433333333333337, 22.8)\n",
      "(26.518518518518526, 22.9)\n",
      "(26.518518518518526, 23.2)\n",
      "(12.800000000000011, 23.5)\n",
      "(26.518518518518526, 23.6)\n",
      "(26.518518518518526, 23.7)\n",
      "(26.518518518518526, 24.4)\n",
      "(30.909090909090903, 24.6)\n",
      "(26.518518518518526, 24.7)\n",
      "(30.909090909090903, 25.3)\n",
      "(26.518518518518526, 25.6)\n",
      "(26.518518518518526, 25.6)\n",
      "(23.6375, 25.7)\n",
      "(20.433333333333337, 25.9)\n",
      "(31.645454545454548, 26.5)\n",
      "(26.518518518518526, 26.6)\n",
      "(44.63157894736842, 26.9)\n",
      "(26.518518518518526, 27.0)\n",
      "(12.800000000000011, 27.0)\n",
      "(26.518518518518526, 27.3)\n",
      "(38.97666666666666, 28.5)\n",
      "(26.518518518518526, 28.6)\n",
      "(51.36363636363637, 29.3)\n",
      "(30.599999999999994, 29.3)\n",
      "(23.6375, 29.4)\n",
      "(30.909090909090903, 29.5)\n",
      "(26.518518518518526, 29.5)\n",
      "(38.97666666666666, 29.7)\n",
      "(38.97666666666666, 29.8)\n",
      "(30.909090909090903, 30.1)\n",
      "(38.97666666666666, 30.5)\n",
      "(30.909090909090903, 30.6)\n",
      "(23.6375, 30.6)\n",
      "(38.97666666666666, 30.9)\n",
      "(26.518518518518526, 31.1)\n",
      "(26.518518518518526, 31.3)\n",
      "(38.97666666666666, 31.5)\n",
      "(26.518518518518526, 31.7)\n",
      "(38.97666666666666, 31.9)\n",
      "(26.518518518518526, 32.1)\n",
      "(38.97666666666666, 32.5)\n",
      "(32.96666666666667, 32.9)\n",
      "(38.97666666666666, 32.9)\n",
      "(38.97666666666666, 33.1)\n",
      "(26.518518518518526, 33.4)\n",
      "(26.518518518518526, 33.4)\n",
      "(38.97666666666666, 34.0)\n",
      "(30.909090909090903, 34.1)\n",
      "(38.97666666666666, 34.2)\n",
      "(38.97666666666666, 34.2)\n",
      "(31.645454545454548, 34.6)\n",
      "(38.97666666666666, 35.1)\n",
      "(38.97666666666666, 35.3)\n",
      "(38.97666666666666, 35.5)\n",
      "(26.518518518518526, 35.6)\n",
      "(44.63157894736842, 36.3)\n",
      "(38.97666666666666, 36.3)\n",
      "(38.97666666666666, 36.5)\n",
      "(38.97666666666666, 36.6)\n",
      "(38.97666666666666, 36.8)\n",
      "(38.97666666666666, 36.8)\n",
      "(43.46, 36.9)\n",
      "(44.63157894736842, 37.2)\n",
      "(31.645454545454548, 37.4)\n",
      "(31.645454545454548, 37.4)\n",
      "(38.97666666666666, 37.4)\n",
      "(31.645454545454548, 37.5)\n",
      "(38.97666666666666, 37.5)\n",
      "(38.97666666666666, 37.5)\n",
      "(41.38, 37.8)\n",
      "(45.4, 37.9)\n",
      "(44.63157894736842, 37.9)\n",
      "(31.645454545454548, 38.1)\n",
      "(38.97666666666666, 38.1)\n",
      "(38.97666666666666, 38.1)\n",
      "(38.97666666666666, 38.6)\n",
      "(41.38, 38.9)\n",
      "(41.38, 39.0)\n",
      "(44.63157894736842, 39.1)\n",
      "(41.38, 39.3)\n",
      "(41.38, 39.4)\n",
      "(44.63157894736842, 39.4)\n",
      "(38.97666666666666, 39.6)\n",
      "(38.97666666666666, 39.6)\n",
      "(38.97666666666666, 39.7)\n",
      "(30.909090909090903, 40.0)\n",
      "(45.900000000000006, 40.1)\n",
      "(31.645454545454548, 40.1)\n",
      "(44.63157894736842, 40.2)\n",
      "(41.38, 40.3)\n",
      "(30.909090909090903, 40.3)\n",
      "(38.97666666666666, 40.3)\n",
      "(38.97666666666666, 40.3)\n",
      "(41.38, 40.5)\n",
      "(38.97666666666666, 40.6)\n",
      "(47.137499999999996, 40.8)\n",
      "(47.137499999999996, 40.9)\n",
      "(38.97666666666666, 41.0)\n",
      "(44.63157894736842, 41.0)\n",
      "(51.36363636363637, 41.2)\n",
      "(12.800000000000011, 41.2)\n",
      "(51.36363636363637, 41.4)\n",
      "(38.97666666666666, 41.4)\n",
      "(47.137499999999996, 41.6)\n",
      "(38.97666666666666, 41.9)\n",
      "(51.36363636363637, 42.0)\n",
      "(51.36363636363637, 42.1)\n",
      "(38.97666666666666, 42.2)\n",
      "(31.645454545454548, 42.3)\n",
      "(38.97666666666666, 42.5)\n",
      "(44.63157894736842, 42.5)\n",
      "(31.645454545454548, 42.6)\n",
      "(44.63157894736842, 42.9)\n",
      "(47.137499999999996, 43.1)\n",
      "(47.137499999999996, 43.2)\n",
      "(40.4, 43.2)\n",
      "(38.97666666666666, 43.4)\n",
      "(45.4, 43.5)\n",
      "(57.425, 44.0)\n",
      "(38.97666666666666, 44.0)\n",
      "(44.63157894736842, 44.3)\n",
      "(47.137499999999996, 44.7)\n",
      "(57.425, 45.1)\n",
      "(30.599999999999994, 45.1)\n",
      "(57.425, 45.4)\n",
      "(45.4, 45.5)\n",
      "(47.137499999999996, 45.5)\n",
      "(51.36363636363637, 46.2)\n",
      "(41.38, 46.8)\n",
      "(38.97666666666666, 47.0)\n",
      "(57.425, 47.3)\n",
      "(51.36363636363637, 47.4)\n",
      "(57.425, 47.9)\n",
      "(40.4, 48.0)\n",
      "(44.63157894736842, 48.0)\n",
      "(38.97666666666666, 48.1)\n",
      "(38.97666666666666, 48.5)\n",
      "(57.425, 48.6)\n",
      "(57.425, 49.0)\n",
      "(51.36363636363637, 49.3)\n",
      "(47.137499999999996, 49.5)\n",
      "(61.89999999999998, 49.8)\n",
      "(47.137499999999996, 50.4)\n",
      "(38.97666666666666, 50.5)\n",
      "(57.425, 50.7)\n",
      "(43.46, 51.6)\n",
      "(57.425, 51.6)\n",
      "(43.46, 51.7)\n",
      "(51.36363636363637, 51.7)\n",
      "(47.137499999999996, 51.8)\n",
      "(43.46, 51.8)\n",
      "(45.4, 52.2)\n",
      "(45.4, 52.2)\n",
      "(47.137499999999996, 52.2)\n",
      "(43.46, 52.5)\n",
      "(57.425, 52.7)\n",
      "(51.36363636363637, 53.0)\n",
      "(51.36363636363637, 53.3)\n",
      "(57.425, 53.5)\n",
      "(57.425, 53.7)\n",
      "(57.425, 54.4)\n",
      "(61.89999999999998, 54.4)\n",
      "(41.38, 54.8)\n",
      "(47.137499999999996, 55.0)\n",
      "(47.137499999999996, 55.0)\n",
      "(45.4, 55.2)\n",
      "(45.4, 55.3)\n",
      "(38.97666666666666, 55.3)\n",
      "(32.96666666666667, 55.9)\n",
      "(47.137499999999996, 56.2)\n",
      "(57.425, 56.3)\n",
      "(57.425, 56.8)\n",
      "(43.46, 56.8)\n",
      "(47.137499999999996, 57.1)\n",
      "(57.425, 58.0)\n",
      "(47.137499999999996, 58.8)\n",
      "(57.425, 59.5)\n",
      "(47.137499999999996, 60.7)\n",
      "(44.63157894736842, 60.7)\n",
      "(38.97666666666666, 61.5)\n",
      "(57.425, 63.2)\n",
      "(44.63157894736842, 63.3)\n",
      "(57.425, 63.9)\n",
      "(44.63157894736842, 67.7)\n",
      "(57.425, 71.0)\n",
      "(57.425, 73.6)\n",
      "(44.63157894736842, 78.0)\n",
      "(44.63157894736842, 78.3)\n"
     ]
    }
   ],
   "source": [
    "# Load up data as dataframe\n",
    "data = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\")\\\n",
    "    .csv(f\"{DATA_ROOT}/realestate.csv\")\n",
    "\n",
    "assembler = VectorAssembler().setInputCols([\"HouseAge\", \"DistanceToMRT\", \\\n",
    "                           \"NumberConvenienceStores\"]).setOutputCol(\"features\")\n",
    "\n",
    "df = assembler.transform(data).select(\"PriceOfUnitArea\", \"features\")\n",
    "\n",
    "# Let's split our data into training data and testing data\n",
    "trainTest = df.randomSplit([0.5, 0.5])\n",
    "trainingDF = trainTest[0]\n",
    "testDF = trainTest[1]\n",
    "\n",
    "# Now create our decision tree\n",
    "dtr = DecisionTreeRegressor().setFeaturesCol(\"features\").setLabelCol(\"PriceOfUnitArea\")\n",
    "\n",
    "# Train the model using our training data\n",
    "model = dtr.fit(trainingDF)\n",
    "\n",
    "# Now see if we can predict values in our test data.\n",
    "# Generate predictions using our decision tree model for all features in our\n",
    "# test dataframe:\n",
    "fullPredictions = model.transform(testDF).cache()\n",
    "\n",
    "# Extract the predictions and the \"known\" correct labels.\n",
    "predictions = fullPredictions.select(\"prediction\").rdd.map(lambda x: x[0])\n",
    "labels = fullPredictions.select(\"PriceOfUnitArea\").rdd.map(lambda x: x[0])\n",
    "\n",
    "# Zip them together\n",
    "predictionAndLabel = predictions.zip(labels).collect()\n",
    "\n",
    "# Print out the predicted and actual values for each point\n",
    "for prediction in predictionAndLabel:\n",
    "  print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e68be5-906b-4a37-b804-79c1aa147b1e",
   "metadata": {},
   "source": [
    "### Customer Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05662ff-16f8-4883-b630-5bdfd1b76a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31af9a-59ff-4c51-b2e6-04635b2f54e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
